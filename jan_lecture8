			Ян. Лекция 8.

Системные вызовы select, poll.

Предположим, есть 2 файловых дескриптора, и мы хотим одновременно с ними работать.
(Сервер, два клиента, клинеты - фд), сервер по очереди работает с ними, если один из них замолчал - висим - плохо.
Решение - можно открывать файл с флагом O_NONBLOCK
fcntl(file control) - можно порулить файловым дескриптором, то есть fdobj;
- ставить и читать всякие флаги

read может выброситься с ошибкой, если мы читать записать в пустой буфер и у него стоит флаг O_NONBLOCK

В чём магия? Можем поставить неблокирующий режим на оба файла и если один замолчал - работаем с другим и наоборот.

Важный/очевидный поинт - когда read из O_NONBLOCK и он возвращает EAGAIN
неправильная интерпретация "я поставил вызов в очередь, попробуй ещё раз, если я уже выполнил и то же самое - я тебе верну" - это posix_aio

todo почитать man posix_aio - идея "потратить на один тред больше и он будет работать синхронно, а остальные будут работать асинхронно"
Тогда чтение из файла будет асинхронным.
aio_read() положит команду в очередь
aio_return() заблочится, пока та команда выполняется или вернёт если уже выполнилась.
 
Есть синглтон-тред, который создаётся при запуске программы, и остальные треды кладут ему задания а он их отвечает.
Типичный producer-consumer

Теперь про select. Идея простая: есть набор пар(fd, event(что мы хотим от этого фд))


poll: [(fd,event)]->[(fd, fired_event)] - говорим, что хотим - возвращает, что реально произошло.
в духе [(1,R/W),(2, R/E)] -> [(1,R)]
poll - блокирующий, а когда он возвращает результаты 0 можем с ними работать неблокирующе.
Если poll вернул write - мы можем гарантированно записать в файловый дескриптор и он не заблокируется.
struct pollfd {
	int fd;
	short events;//requested events
	short revents;//returned events
}	 работает за O(n), где n - количество файловых дескрипторов, которые хотим опросить


Реализация emplace - он заполняет pollfd;

poll - вот такая штука с таймаутом.
select - древняя реализация этого, которой невозможно пользоваться. В винде есть select, но нет poll - потому что,
когда они формировали свой системный стек на основе BSD, в BSD ещё не было poll.
работает за O(количество файловых дескрипторов, которые открыты в программе);

Самая модная тема в этом всём - сигналы. Новые версии poll работают за O(1).
Все эти вызовы работают с сигналами(прерываются ими, всегда крешатся с ошибкой EINTR)
Зачем? Если обработчик сигнала делает что-то существенное, то он может случайно сломать fd.

Утверждается, что поведение poll, epoll,select обусловлено тем, что может случиться в процессе работы.
Всегда прерывается сигналами.


Как это реализовывать?
Есть poll и есть таблица файловых дескрипторов, на которую много тредов ссылается и один из них делает poll.
Берём блокировку на таблицу, бежим по ней и проверяем, если что-то файрится - заполняем pollfd, иначе ставим подписку на файловый дескриптор.
Заводин в каждом fdobj список тредов, которые на него подписаны(). Когда кто-то пишет в пайп - он дёргает fdobj

Если n=0 - мы разбираем массив на кусочки и отдаём соответствующим fdobj - заполняем их.
У процесса есть в этом случае ещё одно состояние "готов выйти из полла" - когда всё заполнено и осталось только отписаться от товарищей.

Очень важный поинт - нужно сначала добавиться в waiting, а потом подписываться, тогда и блокировок никаких не нужно - если нас из waiting 
выкинуло - ну и чёрт с ним.
Есть два процесса, которые шарят один fd.
Есть один процесс, он сделал poll, не оказался в waiting - ему дали управление и он начинает портить файловый дескриптор.
Это работает за О(n)

Что сделать, чтобы было за О(1) 
Идея - разделить задачи.
Создадим системный вызов который пробегает и подписывается.
Ещё один - отписывается.
Таким образом epoll - это poll, разделённый на кусочки
epoll_create -> set<(fd,event)>
epoll_ctl - подписывает и отписывает файловые дескрипторы
epoll_wait - выдаёт объект, который выдали create-ом и он висит, пока на него чего-нибудь не подпишется.

todo man epoll как обычно

epoll_create, epoll_ctl - за О(n)
epoll_wait - за О(1) - лезет по fdobj, проверяет, что очередь eventов пустая, если нет - то дампит её куда?

C epoll можно посоздавать много файловых дескрипторов, потом создать epollfd на их основе,  а все созданные - позакрывать.
epollfd - список, на кого он подписан, список, кто на него подписан и очередь event-ов.

Идея - есть файловый дескриптор, который ссылается на fdobj, который ссылается на обычный файл?
Как реализовать read? Сделали все проверки, добрались до fdobj, потом до fsinode в файловой системе.
VFS занимается менеджментов представления дисковых объектов в памяти, которые нужны, чтобы по ним синхронизироваться

read - wait текущий процесс и просит у fsinode сделать read

read(){
.
.
..

fsinode_read(buf, len, continuation(что нужно выполнить по завершении));
}

fsinode_read{
сгенерировать запрос// create_client_request();
me->waiting//сами кладёмся в waiting
request.subscribe(me, r, r_complete)//подписываемсся на реквест - когда реквест выполнится, реквест должен будет вернуть нас из waiting в ready
//сиречь переложить из очереди r в очередь r_complete - все эти штуки с очередями - альтернативный способ смотреть
//на continuation, удобный для многопоточности
fsinode.push(request)//добавляем реквест в очередь
reshed - переключить контекст(типа yield в ядре)
}

fsinode.push{
r[] = create_io_request(...);//разобраться, какие блоки с винчестера от нас хочет read и для каждого создать io_request
r_n.subscribe(cont, io_complete)//для того, чтобы когда все реквесты будут выполнены, процесс разбудил того, кто его вызвал
r_1...r_n -> iomanager

}

Процесс-обработчик переключается между очередями и перекидывает результаты между ними, как будто instruction pointer.
Традиционный взгляд на опреационную систему - набор очередей, и у каждой очереди сидит чувак, который ждёт определённого ивента.

//Rabbit MQ

1) scheduling до резурсов нижнего уровеня
2) routing из интерраптов в драйвера

менеджер памяти может быть где-то посередине.
Треды в ядре - такие процессы, которые  работают в контексте ядра, но у них нет никаких userspace процессов.

Общение между промежуточными уровнями происходит только через ядро.


cps-преобразование - continuation-passing style





















































